{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:13:56.987729Z",
     "iopub.status.busy": "2022-08-07T05:13:56.987279Z",
     "iopub.status.idle": "2022-08-07T05:13:57.431355Z",
     "shell.execute_reply": "2022-08-07T05:13:57.430280Z",
     "shell.execute_reply.started": "2022-08-07T05:13:56.987689Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:13:57.434969Z",
     "iopub.status.busy": "2022-08-07T05:13:57.434058Z",
     "iopub.status.idle": "2022-08-07T05:14:00.629749Z",
     "shell.execute_reply": "2022-08-07T05:14:00.628747Z",
     "shell.execute_reply.started": "2022-08-07T05:13:57.434937Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724\n",
      "------------------------------\n",
      "['us', 'business', 'leaders', 'lashed', 'out', 'wednesday', 'at', 'legislation', 'that', 'would', 'penalize', 'companies', 'for', 'employing', 'illegal', 'immigrants']\n",
      "['us', 'business', 'attacks', 'tough', 'immigration', 'law']\n",
      "------------------------------\n",
      "['us', 'first', 'lady', 'laura', 'bush', 'and', 'us', 'secretary', 'of', 'state', 'condoleezza', 'rice', 'will', 'represent', 'the', 'united', 'states', 'later', 'this', 'month', 'at', 'the', 'inauguration', 'of', 'liberia', 's', 'president', 'elect', 'ellen', 'johnson', 'sirleaf', 'the', 'white', 'house', 'said', 'wednesday']\n",
      "['laura', 'bush', 'unk', 'rice', 'to', 'attend', 'sirleaf', 's', 'inauguration', 'in', 'liberia']\n",
      "------------------------------\n",
      "['us', 'auto', 'sales', 'will', 'likely', 'be', 'weaker', 'in', 'a', 'senior', 'executive', 'at', 'ford', 'motor', 'company', 'said', 'wednesday']\n",
      "['ford', 'executive', 'sees', 'weaker', 'us', 'auto', 'sales', 'in']\n",
      "------------------------------\n",
      "['us', 'president', 'george', 'w', 'bush', 'said', 'late', 'wednesday', 'that', 'he', 'and', 'the', 'first', 'lady', 'shared', 'the', 'concerns', 'of', 'the', 'israeli', 'people', 'about', 'prime', 'minister', 'ariel', 'sharon', 's', 'health', 'and', 'were', 'praying', 'for', 'his', 'recovery']\n",
      "['bush', 'says', 'he', 'shares', 'israelis', 'concern', 'over', 'sharon']\n",
      "------------------------------\n",
      "['us', 'president', 'george', 'w', 'bush', 'defied', 'congress', 'again', 'wednesday', 'as', 'he', 'placed', 'a', 'slew', 'of', 'controversial', 'political', 'allies', 'in', 'key', 'defense', 'and', 'foreign', 'policy', 'posts', 'in', 'his', 'administration', 'by', 'circumventing', 'the', 'requisite', 'approval', 'process', 'in', 'the', 'senate']\n",
      "['bush', 'defies', 'congress', 'names', 'defense', 'foreign', 'policy', 'posts']\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=50\n",
    "\n",
    "pairs=[]\n",
    "with open('train.txt',encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        word_re=re.compile(r\"\\w+\")\n",
    "        sent,title=line.split('\\t')\n",
    "        sent=word_re.findall(sent.lower())\n",
    "        title=word_re.findall(title.lower())\n",
    "        if len(sent)>MAX_LEN or len(title)>MAX_LEN:\n",
    "            continue\n",
    "\n",
    "        if sent[0] in ['i','you','he','she','we','they','us']:\n",
    "            pairs.append([sent,title])\n",
    "        \n",
    "print(len(pairs))\n",
    "for sent,title in pairs[:5]:\n",
    "    print('-'*30)\n",
    "    print(sent)\n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:14:00.631441Z",
     "iopub.status.busy": "2022-08-07T05:14:00.631018Z",
     "iopub.status.idle": "2022-08-07T05:14:00.651258Z",
     "shell.execute_reply": "2022-08-07T05:14:00.650353Z",
     "shell.execute_reply.started": "2022-08-07T05:14:00.631412Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_vocab={}\n",
    "\n",
    "en_vocab['<pad>'],en_vocab['<bos>'],en_vocab['<eos>']=0,1,2\n",
    "en_idx=3\n",
    "\n",
    "for sent,title in pairs:\n",
    "    for w in sent:\n",
    "        if w not in en_vocab:\n",
    "            en_vocab[w]=en_idx\n",
    "            en_idx+=1\n",
    "    \n",
    "    for w in title:\n",
    "        if w not in en_vocab:\n",
    "            en_vocab[w]=en_idx\n",
    "            en_idx+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:14:00.652833Z",
     "iopub.status.busy": "2022-08-07T05:14:00.652437Z",
     "iopub.status.idle": "2022-08-07T05:14:00.722882Z",
     "shell.execute_reply": "2022-08-07T05:14:00.721909Z",
     "shell.execute_reply.started": "2022-08-07T05:14:00.652803Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1724, 51)\n",
      "(1724, 52)\n",
      "(1724, 52)\n"
     ]
    }
   ],
   "source": [
    "train_sents=[]\n",
    "train_titles=[]\n",
    "train_labels=[]\n",
    "\n",
    "for sent,title in pairs:\n",
    "    train_sent=sent+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(sent))\n",
    "    train_title=[\"<bos>\"]+title+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(title))\n",
    "    train_label=title+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(title)+1)\n",
    "\n",
    "    train_sent.reverse()\n",
    "\n",
    "    train_sents.append([en_vocab[w] for w in train_sent])\n",
    "    train_titles.append([en_vocab[w] for w in train_title])\n",
    "    train_labels.append([en_vocab[w] for w in train_label])\n",
    "\n",
    "train_sents=np.array(train_sents)\n",
    "train_titles=np.array(train_titles)\n",
    "train_labels=np.array(train_labels)\n",
    "\n",
    "print(train_sents.shape)\n",
    "print(train_titles.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:14:00.724558Z",
     "iopub.status.busy": "2022-08-07T05:14:00.724101Z",
     "iopub.status.idle": "2022-08-07T05:14:02.167719Z",
     "shell.execute_reply": "2022-08-07T05:14:02.166347Z",
     "shell.execute_reply.started": "2022-08-07T05:14:00.724527Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:14:02.170650Z",
     "iopub.status.busy": "2022-08-07T05:14:02.169427Z",
     "iopub.status.idle": "2022-08-07T05:14:02.184227Z",
     "shell.execute_reply": "2022-08-07T05:14:02.183417Z",
     "shell.execute_reply.started": "2022-08-07T05:14:02.170593Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7939"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size=128\n",
    "# hidden_size=512\n",
    "layers=1\n",
    "epochs=20\n",
    "batch_size=16\n",
    "en_vocab_size=len(en_vocab)\n",
    "en_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:14:02.186001Z",
     "iopub.status.busy": "2022-08-07T05:14:02.185406Z",
     "iopub.status.idle": "2022-08-07T05:14:02.192404Z",
     "shell.execute_reply": "2022-08-07T05:14:02.191585Z",
     "shell.execute_reply.started": "2022-08-07T05:14:02.185971Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(paddle.nn.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "\n",
    "        self.emb=paddle.nn.Embedding(en_vocab_size,embedding_size)\n",
    "        self.layer=paddle.nn.TransformerEncoderLayer(embedding_size,8,512)\n",
    "        self.encoder=paddle.nn.TransformerEncoder(self.layer,2)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.emb(x)\n",
    "        #[batch_size,MAX_LEN+1,embedding_size]\n",
    "\n",
    "        x=self.encoder(x)\n",
    "        #[batch_size,MAX_LEN+1,embedding_size]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:14:02.194007Z",
     "iopub.status.busy": "2022-08-07T05:14:02.193523Z",
     "iopub.status.idle": "2022-08-07T05:14:02.200961Z",
     "shell.execute_reply": "2022-08-07T05:14:02.200134Z",
     "shell.execute_reply.started": "2022-08-07T05:14:02.193978Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(paddle.nn.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.emb=paddle.nn.Embedding(en_vocab_size,embedding_size)\n",
    "        self.layer=paddle.nn.TransformerDecoderLayer(embedding_size,8,512)\n",
    "        self.decoder=paddle.nn.TransformerDecoder(self.layer,2)\n",
    "\n",
    "        self.outlinear=paddle.nn.Linear(embedding_size,en_vocab_size)\n",
    "\n",
    "    def forward(self,x,en_repr):\n",
    "        x=self.emb(x)\n",
    "        #[batch_size,1,embedding_size]\n",
    "\n",
    "        x=self.decoder(x,en_repr)\n",
    "        #[batch_size,1,embedding_size]\n",
    "\n",
    "        x=self.outlinear(x)\n",
    "        #[batch_size,1,en_vocab_size]\n",
    "\n",
    "        x=paddle.squeeze(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T05:14:02.202379Z",
     "iopub.status.busy": "2022-08-07T05:14:02.202079Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "step: 0,loss: 9.082996368408203\n",
      "step: 50,loss: 1.4103511571884155\n"
     ]
    }
   ],
   "source": [
    "encoder=Encoder()\n",
    "decoder=Decoder()\n",
    "opt=paddle.optimizer.Adam(learning_rate=0.001,parameters=encoder.parameters()+decoder.parameters())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch:{epoch}\")\n",
    "\n",
    "    perm=np.random.permutation(len(train_sents))\n",
    "    train_sents_shuffle=train_sents[perm]\n",
    "    train_labels_shuffle=train_labels[perm]\n",
    "    train_titles_shuffle=train_titles[perm]\n",
    "\n",
    "    for iteration in range(train_sents.shape[0]//batch_size):\n",
    "        x_sents=train_sents_shuffle[iteration*batch_size:(iteration+1)*batch_size]\n",
    "        x_title=train_titles_shuffle[iteration*batch_size:(iteration+1)*batch_size]\n",
    "        y=train_labels_shuffle[iteration*batch_size:(iteration+1)*batch_size]\n",
    "\n",
    "        x_sents=paddle.to_tensor(x_sents)\n",
    "        en_repr=encoder(x_sents)\n",
    "\n",
    "        # hidden=paddle.zeros([batch_size,1,hidden_size])\n",
    "        # cell=paddle.zeros([batch_size,1,hidden_size])\n",
    "\n",
    "        loss=paddle.zeros([1])\n",
    "        for i in range(MAX_LEN+2):\n",
    "            word=x_title[:,i:i+1]\n",
    "            label=y[:,i]\n",
    "            word=paddle.to_tensor(word)\n",
    "            label=paddle.to_tensor(label)\n",
    "\n",
    "            logits=decoder(word,en_repr)\n",
    "            #logits:[batch_size,en_vocab_size]\n",
    "            loss+=F.cross_entropy(logits,label)\n",
    "\n",
    "            # word=paddle.argmax(logits,axis=1)#多余\n",
    "            #word:[batch_size,1]\n",
    "\n",
    "        if iteration%50==0:\n",
    "            print(f\"step: {iteration},loss: {(loss/(MAX_LEN+2)).numpy()[0]}\")\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_grad()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "nums=10\n",
    "indices=np.random.choice(len(train_sents),nums,replace=False)\n",
    "x_sents=train_sents[indices]\n",
    "\n",
    "word=[[en_vocab[\"<bos>\"]]]*nums\n",
    "# hidden=paddle.zeros([nums,1,hidden_size])\n",
    "# cell=paddle.zeros([nums,1,hidden_size])\n",
    "\n",
    "res=[]\n",
    "x_sents=paddle.to_tensor(x_sents)\n",
    "word=paddle.to_tensor(word)\n",
    "en_repr=encoder(x_sents)\n",
    "for i in range(MAX_LEN+2):\n",
    "    #[nums,1]\n",
    "    logits=decoder(word,en_repr)\n",
    "    #[nums,en_vocab_size]\n",
    "    word=paddle.argmax(logits,axis=1)\n",
    "\n",
    "    # print(word.shape)\n",
    "    #[nums]\n",
    "    res.append(word)\n",
    "\n",
    "    word=paddle.unsqueeze(word,axis=-1)\n",
    "\n",
    "res=np.stack(res,axis=-1)\n",
    "\n",
    "for i in range(nums):\n",
    "    x_sent=' '.join(pairs[indices[i]][0])\n",
    "    ground_truth=' '.join(pairs[indices[i]][1])\n",
    "    pred=\"\"\n",
    "    for w in res[i]:\n",
    "        w=list(en_vocab)[w]\n",
    "        if w!=\"<pad>\" and w!=\"<eos>\":\n",
    "            pred+=\" \"+w\n",
    "    \n",
    "    print('-'*30)\n",
    "    print(\"sent:\",x_sent)\n",
    "    print(\"true:\",ground_truth)\n",
    "    print(\"pred:\",pred)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
