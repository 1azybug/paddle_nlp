{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:53.981122Z",
     "iopub.status.busy": "2022-08-07T03:05:53.980616Z",
     "iopub.status.idle": "2022-08-07T03:05:54.186023Z",
     "shell.execute_reply": "2022-08-07T03:05:54.185008Z",
     "shell.execute_reply.started": "2022-08-07T03:05:53.981090Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:54.188791Z",
     "iopub.status.busy": "2022-08-07T03:05:54.188375Z",
     "iopub.status.idle": "2022-08-07T03:05:56.759714Z",
     "shell.execute_reply": "2022-08-07T03:05:56.758536Z",
     "shell.execute_reply.started": "2022-08-07T03:05:54.188756Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724\n",
      "------------------------------\n",
      "['us', 'business', 'leaders', 'lashed', 'out', 'wednesday', 'at', 'legislation', 'that', 'would', 'penalize', 'companies', 'for', 'employing', 'illegal', 'immigrants']\n",
      "['us', 'business', 'attacks', 'tough', 'immigration', 'law']\n",
      "------------------------------\n",
      "['us', 'first', 'lady', 'laura', 'bush', 'and', 'us', 'secretary', 'of', 'state', 'condoleezza', 'rice', 'will', 'represent', 'the', 'united', 'states', 'later', 'this', 'month', 'at', 'the', 'inauguration', 'of', 'liberia', 's', 'president', 'elect', 'ellen', 'johnson', 'sirleaf', 'the', 'white', 'house', 'said', 'wednesday']\n",
      "['laura', 'bush', 'unk', 'rice', 'to', 'attend', 'sirleaf', 's', 'inauguration', 'in', 'liberia']\n",
      "------------------------------\n",
      "['us', 'auto', 'sales', 'will', 'likely', 'be', 'weaker', 'in', 'a', 'senior', 'executive', 'at', 'ford', 'motor', 'company', 'said', 'wednesday']\n",
      "['ford', 'executive', 'sees', 'weaker', 'us', 'auto', 'sales', 'in']\n",
      "------------------------------\n",
      "['us', 'president', 'george', 'w', 'bush', 'said', 'late', 'wednesday', 'that', 'he', 'and', 'the', 'first', 'lady', 'shared', 'the', 'concerns', 'of', 'the', 'israeli', 'people', 'about', 'prime', 'minister', 'ariel', 'sharon', 's', 'health', 'and', 'were', 'praying', 'for', 'his', 'recovery']\n",
      "['bush', 'says', 'he', 'shares', 'israelis', 'concern', 'over', 'sharon']\n",
      "------------------------------\n",
      "['us', 'president', 'george', 'w', 'bush', 'defied', 'congress', 'again', 'wednesday', 'as', 'he', 'placed', 'a', 'slew', 'of', 'controversial', 'political', 'allies', 'in', 'key', 'defense', 'and', 'foreign', 'policy', 'posts', 'in', 'his', 'administration', 'by', 'circumventing', 'the', 'requisite', 'approval', 'process', 'in', 'the', 'senate']\n",
      "['bush', 'defies', 'congress', 'names', 'defense', 'foreign', 'policy', 'posts']\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=50\n",
    "\n",
    "pairs=[]\n",
    "with open('train.txt',encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        word_re=re.compile(r\"\\w+\")\n",
    "        sent,title=line.split('\\t')\n",
    "        sent=word_re.findall(sent.lower())\n",
    "        title=word_re.findall(title.lower())\n",
    "        if len(sent)>MAX_LEN or len(title)>MAX_LEN:\n",
    "            continue\n",
    "\n",
    "        if sent[0] in ['i','you','he','she','we','they','us']:\n",
    "            pairs.append([sent,title])\n",
    "        \n",
    "print(len(pairs))\n",
    "for sent,title in pairs[:5]:\n",
    "    print('-'*30)\n",
    "    print(sent)\n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:56.761958Z",
     "iopub.status.busy": "2022-08-07T03:05:56.761328Z",
     "iopub.status.idle": "2022-08-07T03:05:56.778991Z",
     "shell.execute_reply": "2022-08-07T03:05:56.778269Z",
     "shell.execute_reply.started": "2022-08-07T03:05:56.761926Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_vocab={}\n",
    "\n",
    "en_vocab['<pad>'],en_vocab['<bos>'],en_vocab['<eos>']=0,1,2\n",
    "en_idx=3\n",
    "\n",
    "for sent,title in pairs:\n",
    "    for w in sent:\n",
    "        if w not in en_vocab:\n",
    "            en_vocab[w]=en_idx\n",
    "            en_idx+=1\n",
    "    \n",
    "    for w in title:\n",
    "        if w not in en_vocab:\n",
    "            en_vocab[w]=en_idx\n",
    "            en_idx+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:56.780410Z",
     "iopub.status.busy": "2022-08-07T03:05:56.780053Z",
     "iopub.status.idle": "2022-08-07T03:05:56.897603Z",
     "shell.execute_reply": "2022-08-07T03:05:56.896767Z",
     "shell.execute_reply.started": "2022-08-07T03:05:56.780385Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1724, 51)\n",
      "(1724, 52)\n",
      "(1724, 52)\n"
     ]
    }
   ],
   "source": [
    "train_sents=[]\n",
    "train_titles=[]\n",
    "train_labels=[]\n",
    "\n",
    "for sent,title in pairs:\n",
    "    train_sent=sent+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(sent))\n",
    "    train_title=[\"<bos>\"]+title+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(title))\n",
    "    train_label=title+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(title)+1)\n",
    "\n",
    "    train_sent.reverse()\n",
    "\n",
    "    train_sents.append([en_vocab[w] for w in train_sent])\n",
    "    train_titles.append([en_vocab[w] for w in train_title])\n",
    "    train_labels.append([en_vocab[w] for w in train_label])\n",
    "\n",
    "train_sents=np.array(train_sents)\n",
    "train_titles=np.array(train_titles)\n",
    "train_labels=np.array(train_labels)\n",
    "\n",
    "print(train_sents.shape)\n",
    "print(train_titles.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:56.899848Z",
     "iopub.status.busy": "2022-08-07T03:05:56.899524Z",
     "iopub.status.idle": "2022-08-07T03:05:58.106554Z",
     "shell.execute_reply": "2022-08-07T03:05:58.105358Z",
     "shell.execute_reply.started": "2022-08-07T03:05:56.899813Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:58.108837Z",
     "iopub.status.busy": "2022-08-07T03:05:58.107989Z",
     "iopub.status.idle": "2022-08-07T03:05:58.120716Z",
     "shell.execute_reply": "2022-08-07T03:05:58.119966Z",
     "shell.execute_reply.started": "2022-08-07T03:05:58.108807Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7939"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size=128\n",
    "hidden_size=256\n",
    "layers=1\n",
    "epochs=20\n",
    "batch_size=16\n",
    "en_vocab_size=len(en_vocab)\n",
    "en_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:58.122297Z",
     "iopub.status.busy": "2022-08-07T03:05:58.121768Z",
     "iopub.status.idle": "2022-08-07T03:05:58.127365Z",
     "shell.execute_reply": "2022-08-07T03:05:58.126520Z",
     "shell.execute_reply.started": "2022-08-07T03:05:58.122269Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "\n",
    "        self.emb=paddle.nn.Embedding(en_vocab_size,embedding_size)\n",
    "        self.lstm=paddle.nn.LSTM(embedding_size,hidden_size=hidden_size,num_layers=layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # print(x.shape)\n",
    "        x=self.emb(x)\n",
    "        #x:[batch_size,MAX_LEN+1,embedding_size]\n",
    "        x,(_,_)=self.lstm(x)\n",
    "        #x:[batch_size,MAX_LEN+1,hidden_size]\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:58.128867Z",
     "iopub.status.busy": "2022-08-07T03:05:58.128425Z",
     "iopub.status.idle": "2022-08-07T03:05:58.139202Z",
     "shell.execute_reply": "2022-08-07T03:05:58.138450Z",
     "shell.execute_reply.started": "2022-08-07T03:05:58.128843Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionDecoder(paddle.nn.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AttentionDecoder,self).__init__()\n",
    "        self.emb=paddle.nn.Embedding(en_vocab_size,embedding_size)\n",
    "\n",
    "        self.attention_linear1=paddle.nn.Linear(hidden_size*2,hidden_size)\n",
    "        self.attention_linear2=paddle.nn.Linear(hidden_size,1)\n",
    "\n",
    "        self.lstm=paddle.nn.LSTM(embedding_size+hidden_size,hidden_size=hidden_size,num_layers=layers)\n",
    "\n",
    "        self.outlinear=paddle.nn.Linear(hidden_size,en_vocab_size)\n",
    "    \n",
    "    def forward(self,word,hidden,cell,en_repr):\n",
    "\n",
    "        #word:[batch_size,1]\n",
    "        #hidden,cell:[batch_size,1,hidden_size]\n",
    "        #en_repr:[batch_size,MAX_LEN+1,hidden_size]\n",
    "\n",
    "        word=self.emb(word)\n",
    "        #word:[batch_size,1,embedding_size]\n",
    "\n",
    "        attention_inputs=paddle.concat([paddle.tile(hidden,[1,MAX_LEN+1,1]),en_repr],axis=-1)\n",
    "        #[batch_size,MAX_LEN+1,hidden_size*2]\n",
    "        #last word of title+ every word of sent\n",
    "\n",
    "        attention_inputs=self.attention_linear1(attention_inputs)\n",
    "        attention_inputs=F.tanh(attention_inputs)\n",
    "\n",
    "        attention_inputs=self.attention_linear2(attention_inputs)\n",
    "        #[batch_size,MAX_LEN+1,1]\n",
    "\n",
    "        attention_inputs=paddle.squeeze(attention_inputs)\n",
    "        attention_inputs=F.softmax(attention_inputs)\n",
    "        weights=paddle.unsqueeze(attention_inputs,axis=-1)\n",
    "\n",
    "        weights=paddle.expand_as(weights,en_repr)\n",
    "        \n",
    "        context_vector=paddle.multiply(weights,en_repr)\n",
    "        context_vector=paddle.sum(context_vector,axis=1)\n",
    "        #[batch_size,hidden_size]\n",
    "\n",
    "        context_vector=paddle.unsqueeze(context_vector,axis=1)\n",
    "        #[batch_size,1,hidden_size]\n",
    "\n",
    "        #word:[batch_size,1,embedding_size]\n",
    "        lstm_inputs=paddle.concat([word,context_vector],axis=-1)\n",
    "\n",
    "        hidden=paddle.transpose(hidden,[1,0,2])\n",
    "        cell=paddle.transpose(cell,[1,0,2])\n",
    "        output,(hidden,cell)=self.lstm(lstm_inputs,(hidden,cell))\n",
    "        hidden=paddle.transpose(hidden,[1,0,2])\n",
    "        cell=paddle.transpose(cell,[1,0,2])\n",
    "\n",
    "        #hidden,cell:[batch_size,1,hidden_size]\n",
    "        output=self.outlinear(hidden)\n",
    "        #[batch_size,1,en_vocab_size]\n",
    "        \n",
    "        output=paddle.squeeze(output)\n",
    "        #[batch_size,en_vocab_size]\n",
    "\n",
    "        return output,(hidden,cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:05:58.140451Z",
     "iopub.status.busy": "2022-08-07T03:05:58.140137Z",
     "iopub.status.idle": "2022-08-07T03:11:42.262516Z",
     "shell.execute_reply": "2022-08-07T03:11:42.261491Z",
     "shell.execute_reply.started": "2022-08-07T03:05:58.140429Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 11:05:58.148721  6171 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0807 11:05:58.152729  6171 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "step: 0,loss: 8.987388610839844\n",
      "step: 50,loss: 1.599442720413208\n",
      "step: 100,loss: 1.350903868675232\n",
      "epoch:1\n",
      "step: 0,loss: 1.182124376296997\n",
      "step: 50,loss: 1.2501391172409058\n",
      "step: 100,loss: 1.2571748495101929\n",
      "epoch:2\n",
      "step: 0,loss: 1.0913419723510742\n",
      "step: 50,loss: 1.0296783447265625\n",
      "step: 100,loss: 1.1578869819641113\n",
      "epoch:3\n",
      "step: 0,loss: 1.1276209354400635\n",
      "step: 50,loss: 1.0401471853256226\n",
      "step: 100,loss: 1.1024224758148193\n",
      "epoch:4\n",
      "step: 0,loss: 1.1479531526565552\n",
      "step: 50,loss: 1.168302297592163\n",
      "step: 100,loss: 1.0650542974472046\n",
      "epoch:5\n",
      "step: 0,loss: 0.9886360764503479\n",
      "step: 50,loss: 1.061771035194397\n",
      "step: 100,loss: 1.052024245262146\n",
      "epoch:6\n",
      "step: 0,loss: 0.9993051290512085\n",
      "step: 50,loss: 1.0444704294204712\n",
      "step: 100,loss: 0.9912765622138977\n",
      "epoch:7\n",
      "step: 0,loss: 0.9642326831817627\n",
      "step: 50,loss: 1.0607023239135742\n",
      "step: 100,loss: 0.9567527174949646\n",
      "epoch:8\n",
      "step: 0,loss: 0.9924283027648926\n",
      "step: 50,loss: 1.1005970239639282\n",
      "step: 100,loss: 1.0446380376815796\n",
      "epoch:9\n",
      "step: 0,loss: 0.984419047832489\n",
      "step: 50,loss: 0.9826486110687256\n",
      "step: 100,loss: 0.9164167642593384\n",
      "epoch:10\n",
      "step: 0,loss: 0.8804901242256165\n",
      "step: 50,loss: 0.9451940655708313\n",
      "step: 100,loss: 0.970987856388092\n",
      "epoch:11\n",
      "step: 0,loss: 1.0084114074707031\n",
      "step: 50,loss: 0.9218270778656006\n",
      "step: 100,loss: 0.812741219997406\n",
      "epoch:12\n",
      "step: 0,loss: 0.9223441481590271\n",
      "step: 50,loss: 0.9984824657440186\n",
      "step: 100,loss: 0.9659163951873779\n",
      "epoch:13\n",
      "step: 0,loss: 0.9202435612678528\n",
      "step: 50,loss: 0.8662458658218384\n",
      "step: 100,loss: 0.9691891074180603\n",
      "epoch:14\n",
      "step: 0,loss: 1.02615487575531\n",
      "step: 50,loss: 0.9721646308898926\n",
      "step: 100,loss: 0.8045138716697693\n",
      "epoch:15\n",
      "step: 0,loss: 0.8970293402671814\n",
      "step: 50,loss: 1.1021367311477661\n",
      "step: 100,loss: 0.9363493919372559\n",
      "epoch:16\n",
      "step: 0,loss: 0.8731915950775146\n",
      "step: 50,loss: 0.8205742239952087\n",
      "step: 100,loss: 0.801533579826355\n",
      "epoch:17\n",
      "step: 0,loss: 0.8375887274742126\n",
      "step: 50,loss: 0.8669239282608032\n",
      "step: 100,loss: 0.8325875401496887\n",
      "epoch:18\n",
      "step: 0,loss: 0.8765833973884583\n",
      "step: 50,loss: 0.7219001650810242\n",
      "step: 100,loss: 0.8805500268936157\n",
      "epoch:19\n",
      "step: 0,loss: 0.6969850659370422\n",
      "step: 50,loss: 0.8374649286270142\n",
      "step: 100,loss: 0.8092525601387024\n"
     ]
    }
   ],
   "source": [
    "encoder=Encoder()\n",
    "decoder=AttentionDecoder()\n",
    "opt=paddle.optimizer.Adam(learning_rate=0.001,parameters=encoder.parameters()+decoder.parameters())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"epoch:{epoch}\")\n",
    "\n",
    "    perm=np.random.permutation(len(train_sents))\n",
    "    train_sents_shuffle=train_sents[perm]\n",
    "    train_labels_shuffle=train_labels[perm]\n",
    "    train_titles_shuffle=train_titles[perm]\n",
    "\n",
    "    for iteration in range(train_sents.shape[0]//batch_size):\n",
    "        x_sents=train_sents_shuffle[iteration*batch_size:(iteration+1)*batch_size]\n",
    "        x_title=train_titles_shuffle[iteration*batch_size:(iteration+1)*batch_size]\n",
    "        y=train_labels_shuffle[iteration*batch_size:(iteration+1)*batch_size]\n",
    "\n",
    "        x_sents=paddle.to_tensor(x_sents)\n",
    "        en_repr=encoder(x_sents)\n",
    "\n",
    "        hidden=paddle.zeros([batch_size,1,hidden_size])\n",
    "        cell=paddle.zeros([batch_size,1,hidden_size])\n",
    "\n",
    "        loss=paddle.zeros([1])\n",
    "        for i in range(MAX_LEN+2):\n",
    "            word=x_title[:,i:i+1]\n",
    "            label=y[:,i]\n",
    "            word=paddle.to_tensor(word)\n",
    "            label=paddle.to_tensor(label)\n",
    "\n",
    "            logits,(hidden,cell)=decoder(word,hidden,cell,en_repr)\n",
    "            #logits:[batch_size,en_vocab_size]\n",
    "            loss+=F.cross_entropy(logits,label)\n",
    "\n",
    "            # word=paddle.argmax(logits,axis=1)#多余\n",
    "            #word:[batch_size,1]\n",
    "\n",
    "        if iteration%50==0:\n",
    "            print(f\"step: {iteration},loss: {(loss/(MAX_LEN+2)).numpy()[0]}\")\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_grad()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T03:11:42.266720Z",
     "iopub.status.busy": "2022-08-07T03:11:42.266215Z",
     "iopub.status.idle": "2022-08-07T03:11:42.383301Z",
     "shell.execute_reply": "2022-08-07T03:11:42.382622Z",
     "shell.execute_reply.started": "2022-08-07T03:11:42.266677Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "sent: us forces have arrested the spiritual head of a kurdish islamist group ali abdul aziz and other people in the northern town of halabja an official of the group said sunday\n",
      "true: islamist group in iraqi kurdistan says us army arrested spiritual guide\n",
      "pred:  us airways to visit of the a be a victory\n",
      "------------------------------\n",
      "sent: us federal reserve lrb fed rrb opened a two day meeting on tuesday to discuss the monetary policy in the future with most analysts predicting that the us short term interest rates will be surely raised by percentage point\n",
      "true: us fed opens meeting to discuss future monetary policy\n",
      "pred:  us airways to visit of the a be a victory\n",
      "------------------------------\n",
      "sent: us secretary of state condoleezza rice said wednesday she was satisfied with iraqi government efforts to include minority sunni muslims in the unk process\n",
      "true: rice satisfied with inclusive iraqi political process\n",
      "pred:  us airways to visit on us troops to be unk\n",
      "------------------------------\n",
      "sent: us ambassador to the un john negroponte on thursday repeated his urge for a timely passage of the new security council resolution regulating the june power hand over to the iraqis\n",
      "true: us envoy calls for speedy pass of new iraqi resolution\n",
      "pred:  us president to visit on iraq s iraq s iraq\n",
      "------------------------------\n",
      "sent: us software giant microsoft said wednesday it would comply with a key condition of the european commission to resolve an anti trust row by licensing the source code of its windows operating system\n",
      "true: microsoft to comply with key eu condition in competition row\n",
      "pred:  us airways to visit of us troops to be unk\n",
      "------------------------------\n",
      "sent: he has remained famous far longer than the minutes he promised everyone else so much so that it s hard to travel far these days in los angeles without being confronted by a gigantic portrait of andy warhol\n",
      "true: the world gets another look at andy warhol with unk unk\n",
      "pred:  us airways to visit of the a be a victory\n",
      "------------------------------\n",
      "sent: he tweaked his computer for maximum performance discovered places to hide places to avoid when to be aggressive and when to run away\n",
      "true: area teen has chance at prize playing computer games\n",
      "pred:  us airways to visit of the a be a victory\n",
      "------------------------------\n",
      "sent: us energy reserves fell across the board last week according to government data wednesday that caused crude futures prices to spike\n",
      "true: us fuel reserves all lower\n",
      "pred:  us airways to visit on us troops to be iraq\n",
      "------------------------------\n",
      "sent: us president george w bush said late wednesday that he and the first lady shared the concerns of the israeli people about prime minister ariel sharon s health and were praying for his recovery\n",
      "true: bush says he shares israelis concern over sharon\n",
      "pred:  us airways to visit of us troops to be unk\n",
      "------------------------------\n",
      "sent: us secretary of state condoleezza rice s keynote speech monday on reforms in the middle east was a catalogue of winners and losers as seen by washington in a regional democracy unk\n",
      "true: rice hands out mideast democracy scores\n",
      "pred:  us airways to visit of us troops to be unk\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\r\n",
    "decoder.eval()\r\n",
    "\r\n",
    "nums=10\r\n",
    "indices=np.random.choice(len(train_sents),nums,replace=False)\r\n",
    "x_sents=train_sents[indices]\r\n",
    "\r\n",
    "word=[[en_vocab[\"<bos>\"]]]*nums\r\n",
    "hidden=paddle.zeros([nums,1,hidden_size])\r\n",
    "cell=paddle.zeros([nums,1,hidden_size])\r\n",
    "\r\n",
    "res=[]\r\n",
    "x_sents=paddle.to_tensor(x_sents)\r\n",
    "word=paddle.to_tensor(word)\r\n",
    "en_repr=encoder(x_sents)\r\n",
    "for i in range(MAX_LEN+2):\r\n",
    "    #[nums,1]\r\n",
    "    logits,(hidden,cell)=decoder(word,hidden,cell,en_repr)\r\n",
    "    #[nums,en_vocab_size]\r\n",
    "    word=paddle.argmax(logits,axis=1)\r\n",
    "\r\n",
    "    # print(word.shape)\r\n",
    "    #[nums]\r\n",
    "    res.append(word)\r\n",
    "\r\n",
    "    word=paddle.unsqueeze(word,axis=-1)\r\n",
    "\r\n",
    "res=np.stack(res,axis=-1)\r\n",
    "\r\n",
    "for i in range(nums):\r\n",
    "    x_sent=' '.join(pairs[indices[i]][0])\r\n",
    "    ground_truth=' '.join(pairs[indices[i]][1])\r\n",
    "    pred=\"\"\r\n",
    "    for w in res[i]:\r\n",
    "        w=list(en_vocab)[w]\r\n",
    "        if w!=\"<pad>\" and w!=\"<eos>\":\r\n",
    "            pred+=\" \"+w\r\n",
    "    \r\n",
    "    print('-'*30)\r\n",
    "    print(\"sent:\",x_sent)\r\n",
    "    print(\"true:\",ground_truth)\r\n",
    "    print(\"pred:\",pred)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
