{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:45.443250Z",
     "iopub.status.busy": "2022-08-04T08:08:45.443048Z",
     "iopub.status.idle": "2022-08-04T08:08:46.803038Z",
     "shell.execute_reply": "2022-08-04T08:08:46.802060Z",
     "shell.execute_reply.started": "2022-08-04T08:08:45.443228Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:46.804506Z",
     "iopub.status.busy": "2022-08-04T08:08:46.804068Z",
     "iopub.status.idle": "2022-08-04T08:08:47.072255Z",
     "shell.execute_reply": "2022-08-04T08:08:47.071567Z",
     "shell.execute_reply.started": "2022-08-04T08:08:46.804481Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6784\n",
      "(['you', 'should', 'do', 'the', 'honorable', 'thing', 'and', 'resign'], ['你', '應', '該', '光', '榮', '地', '辭', '職', '。'])\n",
      "(['i', 'am', 'looking', 'forward', 'to', 'hearing', 'from', 'you', 'soon'], ['我', '期', '待', '您', '的', '消', '息', '。'])\n",
      "(['i', 'don', 't', 'want', 'there', 'to', 'be', 'any', 'misunderstanding'], ['我', '不', '想', '有', '任', '何', '误', '会', '。'])\n",
      "(['i', 'like', 'cracking', 'sunflower', 'seeds', 'with', 'my', 'teeth'], ['我', '喜', '欢', '嗑', '葵', '花', '籽', '。'])\n",
      "(['he', 'went', 'to', 'the', 'united', 'states', 'to', 'study', 'medicine'], ['他', '去', '美', '国', '学', '医', '了', '。'])\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=10\n",
    "lines=open('cmn.txt',encoding='utf-8').read().strip().split('\\n')\n",
    "words_re=re.compile(r'\\w+')\n",
    "pairs=[]\n",
    "for l in lines:\n",
    "    en_sent,cn_sent,_=l.split('\\t')\n",
    "    pairs.append((words_re.findall(en_sent.lower()),list(cn_sent)))\n",
    "\n",
    "# print(pairs[:13])\n",
    "\n",
    "filtered_pairs=[]\n",
    "for x in pairs:\n",
    "    if len(x[0])<MAX_LEN and len(x[1])<MAX_LEN and x[0][0] in ('i','you','he','she','they','we'):\n",
    "        filtered_pairs.append(x)\n",
    "\n",
    "print(len(filtered_pairs))\n",
    "\n",
    "for x in filtered_pairs[-5:] :print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:47.074245Z",
     "iopub.status.busy": "2022-08-04T08:08:47.073991Z",
     "iopub.status.idle": "2022-08-04T08:08:47.091745Z",
     "shell.execute_reply": "2022-08-04T08:08:47.091102Z",
     "shell.execute_reply.started": "2022-08-04T08:08:47.074223Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_vocab={}\n",
    "cn_vocab={}\n",
    "en_vocab['<pad>'],en_vocab['<bos>'],en_vocab['<eos>']=0,1,2\n",
    "cn_vocab['<pad>'],cn_vocab['<bos>'],cn_vocab['<eos>']=0,1,2\n",
    "\n",
    "en_idx,cn_idx=3,3\n",
    "for en,cn in filtered_pairs:\n",
    "    for w in en:\n",
    "        if w not in en_vocab:\n",
    "            en_vocab[w]=en_idx\n",
    "            en_idx+=1\n",
    "    for w in cn:\n",
    "        if w not in cn_vocab:\n",
    "            cn_vocab[w]=cn_idx\n",
    "            cn_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:47.092812Z",
     "iopub.status.busy": "2022-08-04T08:08:47.092581Z",
     "iopub.status.idle": "2022-08-04T08:08:47.166375Z",
     "shell.execute_reply": "2022-08-04T08:08:47.165763Z",
     "shell.execute_reply.started": "2022-08-04T08:08:47.092792Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6784, 11)\n",
      "(6784, 12)\n",
      "(6784, 12)\n"
     ]
    }
   ],
   "source": [
    "padded_en_sents=[]\n",
    "padded_cn_sents=[]\n",
    "padded_cn_label_sents=[]\n",
    "\n",
    "for en,cn in filtered_pairs:\n",
    "    padded_en_sent=en+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(en))\n",
    "    # print(padded_en_sent)\n",
    "    padded_en_sent.reverse()\n",
    "    # print(padded_en_sent)\n",
    "    padded_cn_sent=[\"<bos>\"]+cn+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(cn))\n",
    "    padded_cn_label_sent=cn+['<eos>']+['<pad>']*(MAX_LEN-len(cn)+1)\n",
    "\n",
    "    padded_en_sents.append([en_vocab[w] for w in padded_en_sent])\n",
    "    padded_cn_sents.append([cn_vocab[w] for w in padded_cn_sent])\n",
    "    padded_cn_label_sents.append([cn_vocab[w] for w in padded_cn_label_sent])\n",
    "\n",
    "train_en_sents=np.array(padded_en_sents)\n",
    "train_cn_sents=np.array(padded_cn_sents)\n",
    "train_cn_label_sents=np.array(padded_cn_label_sents)\n",
    "\n",
    "print(train_en_sents.shape)\n",
    "print(train_cn_sents.shape)\n",
    "print(train_cn_label_sents.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:47.167493Z",
     "iopub.status.busy": "2022-08-04T08:08:47.167185Z",
     "iopub.status.idle": "2022-08-04T08:08:47.171316Z",
     "shell.execute_reply": "2022-08-04T08:08:47.170692Z",
     "shell.execute_reply.started": "2022-08-04T08:08:47.167472Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_size=128\n",
    "hidden_size=256\n",
    "num_encoder_lstm_layers=1\n",
    "en_vocab_size=len(list(en_vocab))\n",
    "cn_vocab_size=len(list(cn_vocab))\n",
    "\n",
    "epochs=20\n",
    "batch_size=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:47.172321Z",
     "iopub.status.busy": "2022-08-04T08:08:47.172106Z",
     "iopub.status.idle": "2022-08-04T08:08:47.177200Z",
     "shell.execute_reply": "2022-08-04T08:08:47.176558Z",
     "shell.execute_reply.started": "2022-08-04T08:08:47.172301Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.emb=paddle.nn.Embedding(en_vocab_size,embedding_size)\n",
    "        self.lstm=paddle.nn.LSTM(input_size=embedding_size,hidden_size=hidden_size,num_layers=num_encoder_lstm_layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.emb(x)\n",
    "        x,(_,_)=self.lstm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:47.178223Z",
     "iopub.status.busy": "2022-08-04T08:08:47.178004Z",
     "iopub.status.idle": "2022-08-04T08:08:47.185467Z",
     "shell.execute_reply": "2022-08-04T08:08:47.184841Z",
     "shell.execute_reply.started": "2022-08-04T08:08:47.178204Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.emb=paddle.nn.Embedding(cn_vocab_size,embedding_size)\n",
    "        self.lstm=paddle.nn.LSTM(input_size=embedding_size+hidden_size,hidden_size=hidden_size)\n",
    "        self.outlinear=paddle.nn.Linear(hidden_size,cn_vocab_size)\n",
    "    \n",
    "    def forward(self,x,previous_hidden,previous_cell,encoder_outputs):\n",
    "        x=self.emb(x)\n",
    "        # print('-'*30)\n",
    "        # print(encoder_outputs.shape)\n",
    "        context_vector=paddle.sum(encoder_outputs,1)\n",
    "        # print(context_vector.shape)\n",
    "        context_vector=paddle.unsqueeze(context_vector,1)\n",
    "        # print(context_vector.shape)\n",
    "\n",
    "        lstm_input=paddle.concat((x,context_vector),axis=-1)\n",
    "\n",
    "        previous_hidden=paddle.transpose(previous_hidden,[1,0,2])\n",
    "        previous_cell=paddle.transpose(previous_cell,[1,0,2])\n",
    "\n",
    "        x,(hidden,cell)=self.lstm(lstm_input,(previous_hidden,previous_cell))\n",
    "\n",
    "        hidden=paddle.transpose(hidden,[1,0,2])\n",
    "        cell=paddle.transpose(cell,[1,0,2])\n",
    "\n",
    "        output=self.outlinear(hidden)\n",
    "        output=paddle.squeeze(output)\n",
    "        return output,(hidden,cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:47.186467Z",
     "iopub.status.busy": "2022-08-04T08:08:47.186255Z",
     "iopub.status.idle": "2022-08-04T08:12:46.878326Z",
     "shell.execute_reply": "2022-08-04T08:12:46.877343Z",
     "shell.execute_reply.started": "2022-08-04T08:08:47.186449Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 16:08:47.193271 10871 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0804 16:08:47.196259 10871 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "iter 0, loss:[7.6692123]\n",
      "iter 200, loss:[3.9639182]\n",
      "iter 400, loss:[3.2989588]\n",
      "epoch:1\n",
      "iter 0, loss:[3.2058902]\n",
      "iter 200, loss:[3.1991234]\n",
      "iter 400, loss:[3.1223054]\n",
      "epoch:2\n",
      "iter 0, loss:[3.2026477]\n",
      "iter 200, loss:[3.2073016]\n",
      "iter 400, loss:[3.010473]\n",
      "epoch:3\n",
      "iter 0, loss:[3.2029216]\n",
      "iter 200, loss:[3.107572]\n",
      "iter 400, loss:[2.578267]\n",
      "epoch:4\n",
      "iter 0, loss:[2.5719724]\n",
      "iter 200, loss:[2.3629503]\n",
      "iter 400, loss:[2.3354428]\n",
      "epoch:5\n",
      "iter 0, loss:[2.270809]\n",
      "iter 200, loss:[2.2493029]\n",
      "iter 400, loss:[1.9096901]\n",
      "epoch:6\n",
      "iter 0, loss:[2.0700908]\n",
      "iter 200, loss:[1.9801536]\n",
      "iter 400, loss:[1.5809536]\n",
      "epoch:7\n",
      "iter 0, loss:[1.4416498]\n",
      "iter 200, loss:[1.6989276]\n",
      "iter 400, loss:[1.4019668]\n",
      "epoch:8\n",
      "iter 0, loss:[1.4268367]\n",
      "iter 200, loss:[1.6154541]\n",
      "iter 400, loss:[1.6757619]\n",
      "epoch:9\n",
      "iter 0, loss:[1.031613]\n",
      "iter 200, loss:[1.287231]\n",
      "iter 400, loss:[1.106545]\n",
      "epoch:10\n",
      "iter 0, loss:[0.8118762]\n",
      "iter 200, loss:[0.8926243]\n",
      "iter 400, loss:[1.0500791]\n",
      "epoch:11\n",
      "iter 0, loss:[0.86716926]\n",
      "iter 200, loss:[0.9823295]\n",
      "iter 400, loss:[0.9589046]\n",
      "epoch:12\n",
      "iter 0, loss:[0.76300454]\n",
      "iter 200, loss:[0.71362185]\n",
      "iter 400, loss:[0.7026869]\n",
      "epoch:13\n",
      "iter 0, loss:[0.62842655]\n",
      "iter 200, loss:[0.7495426]\n",
      "iter 400, loss:[0.78355646]\n",
      "epoch:14\n",
      "iter 0, loss:[0.46176264]\n",
      "iter 200, loss:[0.7180023]\n",
      "iter 400, loss:[0.3657065]\n",
      "epoch:15\n",
      "iter 0, loss:[0.5072521]\n",
      "iter 200, loss:[0.43625587]\n",
      "iter 400, loss:[0.5471078]\n",
      "epoch:16\n",
      "iter 0, loss:[0.38990662]\n",
      "iter 200, loss:[0.42389628]\n",
      "iter 400, loss:[0.49890074]\n",
      "epoch:17\n",
      "iter 0, loss:[0.2882184]\n",
      "iter 200, loss:[0.3862384]\n",
      "iter 400, loss:[0.34753758]\n",
      "epoch:18\n",
      "iter 0, loss:[0.29140782]\n",
      "iter 200, loss:[0.35899746]\n",
      "iter 400, loss:[0.273974]\n",
      "epoch:19\n",
      "iter 0, loss:[0.26855528]\n",
      "iter 200, loss:[0.18572447]\n",
      "iter 400, loss:[0.21417157]\n"
     ]
    }
   ],
   "source": [
    "encoder=Encoder()\n",
    "decoder=Decoder()\n",
    "\n",
    "opt=paddle.optimizer.Adam(learning_rate=0.001,parameters=encoder.parameters()+decoder.parameters())\n",
    "for epoch in  range(epochs):\n",
    "    print(\"epoch:{}\".format(epoch))\n",
    "    perm=np.random.permutation(len(train_en_sents))\n",
    "    train_en_sents_shuffled=train_en_sents[perm]\n",
    "    train_cn_sents_shuffled=train_cn_sents[perm]\n",
    "    train_cn_label_sents_shuffled=train_cn_label_sents[perm]\n",
    "\n",
    "    for iteration in range(train_en_sents_shuffled.shape[0]//batch_size):\n",
    "        x_data=train_en_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "        sent=paddle.to_tensor(x_data)\n",
    "        en_repr=encoder(sent)\n",
    "\n",
    "        x_cn_data=train_cn_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "        x_cn_label_data=train_cn_label_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "\n",
    "        hidden=paddle.zeros([batch_size,1,hidden_size])\n",
    "        cell=paddle.zeros([batch_size,1,hidden_size])\n",
    "        loss=paddle.zeros([1])\n",
    "\n",
    "        for i in range(MAX_LEN+2):\n",
    "            cn_word=paddle.to_tensor(x_cn_data[:,i:i+1])\n",
    "            cn_word_label=paddle.to_tensor(x_cn_label_data[:,i])\n",
    "\n",
    "            logits,(hidden,cell)=decoder(cn_word,hidden,cell,en_repr)\n",
    "            step_loss=F.cross_entropy(logits,cn_word_label)\n",
    "            loss+=step_loss\n",
    "        \n",
    "        loss=loss/(MAX_LEN+2)\n",
    "        if(iteration % 200==0):\n",
    "            print(\"iter {}, loss:{}\".format(iteration,loss.numpy()))\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:30:11.785446Z",
     "iopub.status.busy": "2022-08-04T08:30:11.784665Z",
     "iopub.status.idle": "2022-08-04T08:30:11.815302Z",
     "shell.execute_reply": "2022-08-04T08:30:11.814615Z",
     "shell.execute_reply.started": "2022-08-04T08:30:11.785414Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i was at home\n",
      "true: 我刚才在家。\n",
      "pred: 我在家裡。\n",
      "you got here fast\n",
      "true: 你來得很快。\n",
      "pred: 你最快快。\n",
      "i played soccer yesterday\n",
      "true: 我昨天踢了足球。\n",
      "pred: 我昨天踢了足球。\n",
      "you do have choices\n",
      "true: 你有选择。\n",
      "pred: 你有选择。\n",
      "i seem to have a fever\n",
      "true: 我好像发烧了。\n",
      "pred: 我好像发烧了。\n",
      "he came in person\n",
      "true: 他亲自来了。\n",
      "pred: 他亲自来了。\n",
      "he told the truth\n",
      "true: 他說了實話。\n",
      "pred: 他说了實話。\n",
      "i got mugged\n",
      "true: 我被抢劫了。\n",
      "pred: 我被抢劫了。\n",
      "i left it on the table\n",
      "true: 我把它留在桌上了。\n",
      "pred: 我把它放在桌上了。\n",
      "they say this old house is haunted\n",
      "true: 據說老房子鬧鬼。\n",
      "pred: 據說老房子鬧鬼。\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "num_of_examples_to_evaluate=10\n",
    "\n",
    "indices=np.random.choice(len(train_en_sents),num_of_examples_to_evaluate,replace=False)\n",
    "x_data=train_en_sents[indices]\n",
    "sent=paddle.to_tensor(x_data)\n",
    "\n",
    "en_repr=encoder(sent)\n",
    "\n",
    "\n",
    "word=np.array([[cn_vocab[\"<bos>\"]]]*num_of_examples_to_evaluate)\n",
    "word=paddle.to_tensor(word)\n",
    "\n",
    "hidden=paddle.zeros([num_of_examples_to_evaluate,1,hidden_size])\n",
    "cell=paddle.zeros([num_of_examples_to_evaluate,1,hidden_size])\n",
    "\n",
    "decoded_sent=[]\n",
    "for i in range(MAX_LEN+2):\n",
    "    logits,(hidden,cell)=decoder(word,hidden,cell,en_repr)\n",
    "    # print('-'*30)\n",
    "    # print(logits.shape)\n",
    "    word=paddle.argmax(logits,axis=-1)\n",
    "    # print(word.shape)\n",
    "    decoded_sent.append(word.numpy())\n",
    "    word=paddle.unsqueeze(word,axis=-1)\n",
    "    # print(word.shape)\n",
    "\n",
    "results=np.stack(decoded_sent,axis=1)\n",
    "for i in range(num_of_examples_to_evaluate):\n",
    "    en_input=' '.join(filtered_pairs[indices[i]][0])\n",
    "    ground_truth_translate=''.join(filtered_pairs[indices[i]][1])\n",
    "    modle_translate=\"\"\n",
    "    for k in results[i]:\n",
    "        w=list(cn_vocab)[k]\n",
    "        if w!='<pad>' and w!= '<eos>':\n",
    "            modle_translate+=w\n",
    "    print(en_input)\n",
    "    print(\"true:\",ground_truth_translate)\n",
    "    print(\"pred:\",modle_translate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
