{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:22:54.708413Z",
     "iopub.status.busy": "2022-08-06T02:22:54.707716Z",
     "iopub.status.idle": "2022-08-06T02:22:56.195247Z",
     "shell.execute_reply": "2022-08-06T02:22:56.194376Z",
     "shell.execute_reply.started": "2022-08-06T02:22:54.708360Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:22:56.198071Z",
     "iopub.status.busy": "2022-08-06T02:22:56.197398Z",
     "iopub.status.idle": "2022-08-06T02:22:56.527645Z",
     "shell.execute_reply": "2022-08-06T02:22:56.526588Z",
     "shell.execute_reply.started": "2022-08-06T02:22:56.198038Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6784\n",
      "(['you', 'should', 'do', 'the', 'honorable', 'thing', 'and', 'resign'], ['你', '應', '該', '光', '榮', '地', '辭', '職', '。'])\n",
      "(['i', 'am', 'looking', 'forward', 'to', 'hearing', 'from', 'you', 'soon'], ['我', '期', '待', '您', '的', '消', '息', '。'])\n",
      "(['i', 'don', 't', 'want', 'there', 'to', 'be', 'any', 'misunderstanding'], ['我', '不', '想', '有', '任', '何', '误', '会', '。'])\n",
      "(['i', 'like', 'cracking', 'sunflower', 'seeds', 'with', 'my', 'teeth'], ['我', '喜', '欢', '嗑', '葵', '花', '籽', '。'])\n",
      "(['he', 'went', 'to', 'the', 'united', 'states', 'to', 'study', 'medicine'], ['他', '去', '美', '国', '学', '医', '了', '。'])\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=10\n",
    "lines=open('cmn.txt',encoding='utf-8').read().strip().split('\\n')\n",
    "words_re=re.compile(r'\\w+')\n",
    "pairs=[]\n",
    "for l in lines:\n",
    "    en_sent,cn_sent,_=l.split('\\t')\n",
    "    pairs.append((words_re.findall(en_sent.lower()),list(cn_sent)))\n",
    "\n",
    "# print(pairs[:13])\n",
    "\n",
    "filtered_pairs=[]\n",
    "for x in pairs:\n",
    "    if len(x[0])<MAX_LEN and len(x[1])<MAX_LEN and x[0][0] in ('i','you','he','she','they','we'):\n",
    "        filtered_pairs.append(x)\n",
    "\n",
    "print(len(filtered_pairs))\n",
    "\n",
    "for x in filtered_pairs[-5:] :print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:22:56.529968Z",
     "iopub.status.busy": "2022-08-06T02:22:56.529164Z",
     "iopub.status.idle": "2022-08-06T02:22:56.550938Z",
     "shell.execute_reply": "2022-08-06T02:22:56.549985Z",
     "shell.execute_reply.started": "2022-08-06T02:22:56.529920Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en_vocab={}\n",
    "cn_vocab={}\n",
    "en_vocab['<pad>'],en_vocab['<bos>'],en_vocab['<eos>']=0,1,2\n",
    "cn_vocab['<pad>'],cn_vocab['<bos>'],cn_vocab['<eos>']=0,1,2\n",
    "\n",
    "en_idx,cn_idx=3,3\n",
    "for en,cn in filtered_pairs:\n",
    "    for w in en:\n",
    "        if w not in en_vocab:\n",
    "            en_vocab[w]=en_idx\n",
    "            en_idx+=1\n",
    "    for w in cn:\n",
    "        if w not in cn_vocab:\n",
    "            cn_vocab[w]=cn_idx\n",
    "            cn_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:22:56.552425Z",
     "iopub.status.busy": "2022-08-06T02:22:56.552083Z",
     "iopub.status.idle": "2022-08-06T02:22:56.627478Z",
     "shell.execute_reply": "2022-08-06T02:22:56.626792Z",
     "shell.execute_reply.started": "2022-08-06T02:22:56.552400Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6784, 11)\n",
      "(6784, 12)\n",
      "(6784, 12)\n"
     ]
    }
   ],
   "source": [
    "padded_en_sents=[]\n",
    "padded_cn_sents=[]\n",
    "padded_cn_label_sents=[]\n",
    "\n",
    "for en,cn in filtered_pairs:\n",
    "    padded_en_sent=en+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(en))\n",
    "    # print(padded_en_sent)\n",
    "    padded_en_sent.reverse()\n",
    "    # print(padded_en_sent)\n",
    "    padded_cn_sent=[\"<bos>\"]+cn+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(cn))\n",
    "    padded_cn_label_sent=cn+['<eos>']+['<pad>']*(MAX_LEN-len(cn)+1)\n",
    "\n",
    "    padded_en_sents.append([en_vocab[w] for w in padded_en_sent])\n",
    "    padded_cn_sents.append([cn_vocab[w] for w in padded_cn_sent])\n",
    "    padded_cn_label_sents.append([cn_vocab[w] for w in padded_cn_label_sent])\n",
    "\n",
    "train_en_sents=np.array(padded_en_sents)\n",
    "train_cn_sents=np.array(padded_cn_sents)\n",
    "train_cn_label_sents=np.array(padded_cn_label_sents)\n",
    "\n",
    "print(train_en_sents.shape)\n",
    "print(train_cn_sents.shape)\n",
    "print(train_cn_label_sents.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:22:56.628790Z",
     "iopub.status.busy": "2022-08-06T02:22:56.628446Z",
     "iopub.status.idle": "2022-08-06T02:22:56.632688Z",
     "shell.execute_reply": "2022-08-06T02:22:56.632044Z",
     "shell.execute_reply.started": "2022-08-06T02:22:56.628755Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_size=128\n",
    "hidden_size=256\n",
    "num_encoder_lstm_layers=1\n",
    "en_vocab_size=len(list(en_vocab))\n",
    "cn_vocab_size=len(list(cn_vocab))\n",
    "\n",
    "epochs=20\n",
    "batch_size=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:22:56.633944Z",
     "iopub.status.busy": "2022-08-06T02:22:56.633560Z",
     "iopub.status.idle": "2022-08-06T02:22:56.638846Z",
     "shell.execute_reply": "2022-08-06T02:22:56.638209Z",
     "shell.execute_reply.started": "2022-08-06T02:22:56.633921Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.emb=paddle.nn.Embedding(en_vocab_size,embedding_size)\n",
    "        self.lstm=paddle.nn.LSTM(input_size=embedding_size,hidden_size=hidden_size,num_layers=num_encoder_lstm_layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.emb(x)\n",
    "        x,(_,_)=self.lstm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-AttentionDecoder 模型配置(只有这里和上一个实践不同)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:22:56.640134Z",
     "iopub.status.busy": "2022-08-06T02:22:56.639699Z",
     "iopub.status.idle": "2022-08-06T02:22:56.649112Z",
     "shell.execute_reply": "2022-08-06T02:22:56.648490Z",
     "shell.execute_reply.started": "2022-08-06T02:22:56.640111Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionDecoder(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(AttentionDecoder,self).__init__()\n",
    "        self.emb=paddle.nn.Embedding(cn_vocab_size,embedding_size)\n",
    "        self.lstm=paddle.nn.LSTM(input_size=embedding_size+hidden_size,hidden_size=hidden_size)\n",
    "\n",
    "        self.attention_linear1=paddle.nn.Linear(hidden_size*2,hidden_size)\n",
    "        self.attention_linear2=paddle.nn.Linear(hidden_size,1)\n",
    "\n",
    "        self.outlinear=paddle.nn.Linear(hidden_size,cn_vocab_size)\n",
    "    \n",
    "    def forward(self,x,previous_hidden,previous_cell,encoder_outputs):\n",
    "        x=self.emb(x)\n",
    "\n",
    "\n",
    "        attention_inputs=paddle.concat((encoder_outputs,paddle.tile(previous_hidden,repeat_times=[1,MAX_LEN+1,1])),axis=-1)\n",
    "        attention_hidden=self.attention_linear1(attention_inputs)\n",
    "        attention_hidden=F.tanh(attention_hidden)\n",
    "\n",
    "        attention_logits=self.attention_linear2(attention_hidden)\n",
    "        \n",
    "        attention_logits=paddle.squeeze(attention_logits)\n",
    "        attention_weights=F.softmax(attention_logits)\n",
    "        attention_weights=paddle.expand_as(paddle.unsqueeze(attention_weights,-1),encoder_outputs)\n",
    "\n",
    "        context_vector=paddle.multiply(encoder_outputs,attention_weights)\n",
    "        context_vector=paddle.sum(context_vector,1)\n",
    "        context_vector=paddle.unsqueeze(context_vector,1)\n",
    "\n",
    "\n",
    "        lstm_input=paddle.concat((x,context_vector),axis=-1)\n",
    "        previous_hidden=paddle.transpose(previous_hidden,[1,0,2])\n",
    "        previous_cell=paddle.transpose(previous_cell,[1,0,2])\n",
    "\n",
    "        x,(hidden,cell)=self.lstm(lstm_input,(previous_hidden,previous_cell))\n",
    "        \n",
    "        hidden=paddle.transpose(hidden,[1,0,2])\n",
    "        cell=paddle.transpose(cell,[1,0,2])\n",
    "\n",
    "        output=self.outlinear(hidden)\n",
    "        output=paddle.squeeze(output)\n",
    "\n",
    "        return output,(hidden,cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T01:51:26.419414Z",
     "iopub.status.busy": "2022-08-06T01:51:26.418437Z",
     "iopub.status.idle": "2022-08-06T01:51:26.430619Z",
     "shell.execute_reply": "2022-08-06T01:51:26.429384Z",
     "shell.execute_reply.started": "2022-08-06T01:51:26.419370Z"
    }
   },
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:22:56.650498Z",
     "iopub.status.busy": "2022-08-06T02:22:56.650050Z",
     "iopub.status.idle": "2022-08-06T02:28:53.975510Z",
     "shell.execute_reply": "2022-08-06T02:28:53.974610Z",
     "shell.execute_reply.started": "2022-08-06T02:22:56.650475Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 10:22:56.657261   700 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0806 10:22:56.661391   700 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "iter 0, loss:[7.683391]\n",
      "iter 200, loss:[3.120678]\n",
      "iter 400, loss:[3.1328294]\n",
      "epoch:1\n",
      "iter 0, loss:[2.8534687]\n",
      "iter 200, loss:[2.5909526]\n",
      "iter 400, loss:[2.595067]\n",
      "epoch:2\n",
      "iter 0, loss:[2.5150201]\n",
      "iter 200, loss:[2.48274]\n",
      "iter 400, loss:[2.3937104]\n",
      "epoch:3\n",
      "iter 0, loss:[2.6956944]\n",
      "iter 200, loss:[2.3992543]\n",
      "iter 400, loss:[2.3842678]\n",
      "epoch:4\n",
      "iter 0, loss:[2.3324437]\n",
      "iter 200, loss:[1.9485701]\n",
      "iter 400, loss:[1.8910669]\n",
      "epoch:5\n",
      "iter 0, loss:[1.8418152]\n",
      "iter 200, loss:[1.8176267]\n",
      "iter 400, loss:[1.6164421]\n",
      "epoch:6\n",
      "iter 0, loss:[1.7416186]\n",
      "iter 200, loss:[1.5939775]\n",
      "iter 400, loss:[1.5162796]\n",
      "epoch:7\n",
      "iter 0, loss:[1.286771]\n",
      "iter 200, loss:[1.4252247]\n",
      "iter 400, loss:[1.7099051]\n",
      "epoch:8\n",
      "iter 0, loss:[1.366365]\n",
      "iter 200, loss:[1.4557322]\n",
      "iter 400, loss:[1.3257641]\n",
      "epoch:9\n",
      "iter 0, loss:[1.2669723]\n",
      "iter 200, loss:[1.2047687]\n",
      "iter 400, loss:[1.0214838]\n",
      "epoch:10\n",
      "iter 0, loss:[1.2424362]\n",
      "iter 200, loss:[1.3565617]\n",
      "iter 400, loss:[1.0956166]\n",
      "epoch:11\n",
      "iter 0, loss:[0.7367716]\n",
      "iter 200, loss:[0.9736609]\n",
      "iter 400, loss:[1.0294664]\n",
      "epoch:12\n",
      "iter 0, loss:[0.85158557]\n",
      "iter 200, loss:[0.77432513]\n",
      "iter 400, loss:[1.0098165]\n",
      "epoch:13\n",
      "iter 0, loss:[0.86165994]\n",
      "iter 200, loss:[0.73552024]\n",
      "iter 400, loss:[0.81538296]\n",
      "epoch:14\n",
      "iter 0, loss:[0.7658067]\n",
      "iter 200, loss:[0.61517817]\n",
      "iter 400, loss:[0.5725261]\n",
      "epoch:15\n",
      "iter 0, loss:[0.5170812]\n",
      "iter 200, loss:[0.5099368]\n",
      "iter 400, loss:[0.43868443]\n",
      "epoch:16\n",
      "iter 0, loss:[0.5459668]\n",
      "iter 200, loss:[0.4823687]\n",
      "iter 400, loss:[0.51616806]\n",
      "epoch:17\n",
      "iter 0, loss:[0.4218859]\n",
      "iter 200, loss:[0.3390307]\n",
      "iter 400, loss:[0.63970184]\n",
      "epoch:18\n",
      "iter 0, loss:[0.29563785]\n",
      "iter 200, loss:[0.35351098]\n",
      "iter 400, loss:[0.28249353]\n",
      "epoch:19\n",
      "iter 0, loss:[0.33185077]\n",
      "iter 200, loss:[0.3793667]\n",
      "iter 400, loss:[0.31761178]\n"
     ]
    }
   ],
   "source": [
    "encoder=Encoder()\n",
    "decoder=AttentionDecoder()\n",
    "\n",
    "opt=paddle.optimizer.Adam(learning_rate=0.001,parameters=encoder.parameters()+decoder.parameters())\n",
    "for epoch in  range(epochs):\n",
    "    print(\"epoch:{}\".format(epoch))\n",
    "    perm=np.random.permutation(len(train_en_sents))\n",
    "    train_en_sents_shuffled=train_en_sents[perm]\n",
    "    train_cn_sents_shuffled=train_cn_sents[perm]\n",
    "    train_cn_label_sents_shuffled=train_cn_label_sents[perm]\n",
    "\n",
    "    for iteration in range(train_en_sents_shuffled.shape[0]//batch_size):\n",
    "        x_data=train_en_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "        sent=paddle.to_tensor(x_data)\n",
    "        en_repr=encoder(sent)\n",
    "\n",
    "        x_cn_data=train_cn_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "        x_cn_label_data=train_cn_label_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "\n",
    "        hidden=paddle.zeros([batch_size,1,hidden_size])\n",
    "        cell=paddle.zeros([batch_size,1,hidden_size])\n",
    "        loss=paddle.zeros([1])\n",
    "\n",
    "        for i in range(MAX_LEN+2):\n",
    "            cn_word=paddle.to_tensor(x_cn_data[:,i:i+1])\n",
    "            cn_word_label=paddle.to_tensor(x_cn_label_data[:,i])\n",
    "\n",
    "            logits,(hidden,cell)=decoder(cn_word,hidden,cell,en_repr)\n",
    "            step_loss=F.cross_entropy(logits,cn_word_label)\n",
    "            loss+=step_loss\n",
    "        \n",
    "        loss=loss/(MAX_LEN+2)\n",
    "        if(iteration % 200==0):\n",
    "            print(\"iter {}, loss:{}\".format(iteration,loss.numpy()))\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T02:28:53.977348Z",
     "iopub.status.busy": "2022-08-06T02:28:53.976940Z",
     "iopub.status.idle": "2022-08-06T02:28:54.014856Z",
     "shell.execute_reply": "2022-08-06T02:28:54.014154Z",
     "shell.execute_reply.started": "2022-08-06T02:28:53.977320Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i took the elevator to the fourth floor\n",
      "true: 我搭电梯去了四楼。\n",
      "pred: 我去了三楼前。\n",
      "i just wasn t paying attention\n",
      "true: 我只是没注意。\n",
      "pred: 我只是没注意。\n",
      "he raised his hands\n",
      "true: 他舉起了他的手。\n",
      "pred: 他舉起了他的手。\n",
      "you did a good job\n",
      "true: 你干得很好。\n",
      "pred: 你做了很多的。\n",
      "i like you\n",
      "true: 我喜欢你！\n",
      "pred: 我喜欢你。\n",
      "i have almost no money with me\n",
      "true: 我身上幾乎沒有錢。\n",
      "pred: 我身上幾乎沒有錢。\n",
      "i don t think anyone can do this\n",
      "true: 我认为没人能做到。\n",
      "pred: 我認為沒看不到它。\n",
      "we re eating apples\n",
      "true: 我們在吃蘋果。\n",
      "pred: 我們在吃蘋果。\n",
      "she sat on the bench\n",
      "true: 她坐在長椅上。\n",
      "pred: 她坐在長椅上。\n",
      "he can read english easily\n",
      "true: 他能轻松地读英语。\n",
      "pred: 他能轻松英语。\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "num_of_examples_to_evaluate=10\n",
    "\n",
    "indices=np.random.choice(len(train_en_sents),num_of_examples_to_evaluate,replace=False)\n",
    "x_data=train_en_sents[indices]\n",
    "sent=paddle.to_tensor(x_data)\n",
    "\n",
    "en_repr=encoder(sent)\n",
    "\n",
    "\n",
    "word=np.array([[cn_vocab[\"<bos>\"]]]*num_of_examples_to_evaluate)\n",
    "word=paddle.to_tensor(word)\n",
    "\n",
    "hidden=paddle.zeros([num_of_examples_to_evaluate,1,hidden_size])\n",
    "cell=paddle.zeros([num_of_examples_to_evaluate,1,hidden_size])\n",
    "\n",
    "decoded_sent=[]\n",
    "for i in range(MAX_LEN+2):\n",
    "    logits,(hidden,cell)=decoder(word,hidden,cell,en_repr)\n",
    "    # print('-'*30)\n",
    "    # print(logits.shape)\n",
    "    word=paddle.argmax(logits,axis=-1)\n",
    "    # print(word.shape)\n",
    "    decoded_sent.append(word.numpy())\n",
    "    word=paddle.unsqueeze(word,axis=-1)\n",
    "    # print(word.shape)\n",
    "\n",
    "results=np.stack(decoded_sent,axis=1)\n",
    "for i in range(num_of_examples_to_evaluate):\n",
    "    en_input=' '.join(filtered_pairs[indices[i]][0])\n",
    "    ground_truth_translate=''.join(filtered_pairs[indices[i]][1])\n",
    "    modle_translate=\"\"\n",
    "    for k in results[i]:\n",
    "        w=list(cn_vocab)[k]\n",
    "        if w!='<pad>' and w!= '<eos>':\n",
    "            modle_translate+=w\n",
    "    print(en_input)\n",
    "    print(\"true:\",ground_truth_translate)\n",
    "    print(\"pred:\",modle_translate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
