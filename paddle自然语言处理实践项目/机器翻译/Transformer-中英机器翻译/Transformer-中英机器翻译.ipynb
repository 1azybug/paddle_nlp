{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:04:12.671868Z",
     "iopub.status.busy": "2022-08-06T11:04:12.671551Z",
     "iopub.status.idle": "2022-08-06T11:04:14.028100Z",
     "shell.execute_reply": "2022-08-06T11:04:14.027207Z",
     "shell.execute_reply.started": "2022-08-06T11:04:12.671848Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:04:14.030012Z",
     "iopub.status.busy": "2022-08-06T11:04:14.029233Z",
     "iopub.status.idle": "2022-08-06T11:04:14.292814Z",
     "shell.execute_reply": "2022-08-06T11:04:14.292009Z",
     "shell.execute_reply.started": "2022-08-06T11:04:14.029985Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6784\n",
      "(['you', 'should', 'do', 'the', 'honorable', 'thing', 'and', 'resign'], ['你', '應', '該', '光', '榮', '地', '辭', '職', '。'])\n",
      "(['i', 'am', 'looking', 'forward', 'to', 'hearing', 'from', 'you', 'soon'], ['我', '期', '待', '您', '的', '消', '息', '。'])\n",
      "(['i', 'don', 't', 'want', 'there', 'to', 'be', 'any', 'misunderstanding'], ['我', '不', '想', '有', '任', '何', '误', '会', '。'])\n",
      "(['i', 'like', 'cracking', 'sunflower', 'seeds', 'with', 'my', 'teeth'], ['我', '喜', '欢', '嗑', '葵', '花', '籽', '。'])\n",
      "(['he', 'went', 'to', 'the', 'united', 'states', 'to', 'study', 'medicine'], ['他', '去', '美', '国', '学', '医', '了', '。'])\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=10\n",
    "lines=open('cmn.txt',encoding='utf-8').read().strip().split('\\n')\n",
    "words_re=re.compile(r'\\w+')\n",
    "pairs=[]\n",
    "for l in lines:\n",
    "    en_sent,cn_sent,_=l.split('\\t')\n",
    "    pairs.append((words_re.findall(en_sent.lower()),list(cn_sent)))\n",
    "\n",
    "# print(pairs[:13])\n",
    "\n",
    "filtered_pairs=[]\n",
    "for x in pairs:\n",
    "    if len(x[0])<MAX_LEN and len(x[1])<MAX_LEN and x[0][0] in ('i','you','he','she','they','we'):\n",
    "        filtered_pairs.append(x)\n",
    "\n",
    "print(len(filtered_pairs))\n",
    "\n",
    "for x in filtered_pairs[-5:] :print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:04:14.295167Z",
     "iopub.status.busy": "2022-08-06T11:04:14.294595Z",
     "iopub.status.idle": "2022-08-06T11:04:14.312128Z",
     "shell.execute_reply": "2022-08-06T11:04:14.311479Z",
     "shell.execute_reply.started": "2022-08-06T11:04:14.295141Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en_vocab={}\n",
    "cn_vocab={}\n",
    "en_vocab['<pad>'],en_vocab['<bos>'],en_vocab['<eos>']=0,1,2\n",
    "cn_vocab['<pad>'],cn_vocab['<bos>'],cn_vocab['<eos>']=0,1,2\n",
    "\n",
    "en_idx,cn_idx=3,3\n",
    "for en,cn in filtered_pairs:\n",
    "    for w in en:\n",
    "        if w not in en_vocab:\n",
    "            en_vocab[w]=en_idx\n",
    "            en_idx+=1\n",
    "    for w in cn:\n",
    "        if w not in cn_vocab:\n",
    "            cn_vocab[w]=cn_idx\n",
    "            cn_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:04:14.313441Z",
     "iopub.status.busy": "2022-08-06T11:04:14.312973Z",
     "iopub.status.idle": "2022-08-06T11:04:14.382862Z",
     "shell.execute_reply": "2022-08-06T11:04:14.382179Z",
     "shell.execute_reply.started": "2022-08-06T11:04:14.313418Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6784, 11)\n",
      "(6784, 12)\n",
      "(6784, 12)\n"
     ]
    }
   ],
   "source": [
    "padded_en_sents=[]\n",
    "padded_cn_sents=[]\n",
    "padded_cn_label_sents=[]\n",
    "\n",
    "for en,cn in filtered_pairs:\n",
    "    padded_en_sent=en+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(en))\n",
    "    # print(padded_en_sent)\n",
    "    padded_en_sent.reverse()\n",
    "    # print(padded_en_sent)\n",
    "    padded_cn_sent=[\"<bos>\"]+cn+[\"<eos>\"]+[\"<pad>\"]*(MAX_LEN-len(cn))\n",
    "    padded_cn_label_sent=cn+['<eos>']+['<pad>']*(MAX_LEN-len(cn)+1)\n",
    "\n",
    "    padded_en_sents.append([en_vocab[w] for w in padded_en_sent])\n",
    "    padded_cn_sents.append([cn_vocab[w] for w in padded_cn_sent])\n",
    "    padded_cn_label_sents.append([cn_vocab[w] for w in padded_cn_label_sent])\n",
    "\n",
    "train_en_sents=np.array(padded_en_sents)\n",
    "train_cn_sents=np.array(padded_cn_sents)\n",
    "train_cn_label_sents=np.array(padded_cn_label_sents)\n",
    "\n",
    "print(train_en_sents.shape)\n",
    "print(train_cn_sents.shape)\n",
    "print(train_cn_label_sents.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:04:14.383892Z",
     "iopub.status.busy": "2022-08-06T11:04:14.383692Z",
     "iopub.status.idle": "2022-08-06T11:04:14.386857Z",
     "shell.execute_reply": "2022-08-06T11:04:14.386251Z",
     "shell.execute_reply.started": "2022-08-06T11:04:14.383872Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddle.nn import TransformerEncoderLayer,TransformerEncoder,TransformerDecoderLayer,TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:04:14.388092Z",
     "iopub.status.busy": "2022-08-06T11:04:14.387658Z",
     "iopub.status.idle": "2022-08-06T11:04:14.391158Z",
     "shell.execute_reply": "2022-08-06T11:04:14.390560Z",
     "shell.execute_reply.started": "2022-08-06T11:04:14.388072Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_size=128\n",
    "hidden_size=512\n",
    "num_encoder_lstm_layers=1\n",
    "en_vocab_size=len(list(en_vocab))\n",
    "cn_vocab_size=len(list(cn_vocab))\n",
    "\n",
    "epochs=20\n",
    "batch_size=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:04:14.392439Z",
     "iopub.status.busy": "2022-08-06T11:04:14.392003Z",
     "iopub.status.idle": "2022-08-06T11:04:14.398818Z",
     "shell.execute_reply": "2022-08-06T11:04:14.398217Z",
     "shell.execute_reply.started": "2022-08-06T11:04:14.392418Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(paddle.nn.Layer):\n",
    "    def __init__(self,en_vocab_size,embedding_size,num_layers=2,head_number=2,middle_units=512):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.emb=paddle.nn.Embedding(en_vocab_size,embedding_size)\n",
    "        encoder_layer=TransformerEncoderLayer(embedding_size,head_number,middle_units)\n",
    "        self.encoder=TransformerEncoder(encoder_layer,num_layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.emb(x)\n",
    "        en_out=self.encoder(x)\n",
    "        return en_out\n",
    "    \n",
    "class Decoder(paddle.nn.Layer):\n",
    "    def __init__(self,cn_vocab_size,embedding_size,num_layers=2,head_number=2,middle_units=512):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.emb=paddle.nn.Embedding(cn_vocab_size,embedding_size)\n",
    "\n",
    "        decoder_layer=TransformerDecoderLayer(embedding_size,head_number,middle_units)\n",
    "        self.decoder=TransformerDecoder(decoder_layer,num_layers)\n",
    "\n",
    "        self.outlinear=paddle.nn.Linear(embedding_size,cn_vocab_size)\n",
    "\n",
    "    def forward(self,x,encoder_outputs):\n",
    "        x=self.emb(x)\n",
    "        de_out=self.decoder(x,encoder_outputs)\n",
    "        output=self.outlinear(de_out)\n",
    "        output=paddle.squeeze(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:04:14.400044Z",
     "iopub.status.busy": "2022-08-06T11:04:14.399614Z",
     "iopub.status.idle": "2022-08-06T11:20:32.079381Z",
     "shell.execute_reply": "2022-08-06T11:20:32.078353Z",
     "shell.execute_reply.started": "2022-08-06T11:04:14.400023Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 19:04:14.405814   347 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W0806 19:04:14.408393   347 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "iter 0, loss:[7.8213344]\n",
      "iter 50, loss:[7.129674]\n",
      "iter 100, loss:[6.9309206]\n",
      "iter 150, loss:[6.7554655]\n",
      "iter 200, loss:[6.4796467]\n",
      "iter 250, loss:[6.3123894]\n",
      "iter 300, loss:[6.1580744]\n",
      "iter 350, loss:[6.157483]\n",
      "iter 400, loss:[5.784957]\n",
      "epoch:1\n",
      "iter 0, loss:[5.8144426]\n",
      "iter 50, loss:[5.5928516]\n",
      "iter 100, loss:[5.72377]\n",
      "iter 150, loss:[5.548216]\n",
      "iter 200, loss:[5.644553]\n",
      "iter 250, loss:[5.3269114]\n",
      "iter 300, loss:[5.4419055]\n",
      "iter 350, loss:[5.394272]\n",
      "iter 400, loss:[5.4558554]\n",
      "epoch:2\n",
      "iter 0, loss:[5.3960285]\n",
      "iter 50, loss:[5.065187]\n",
      "iter 100, loss:[5.376636]\n",
      "iter 150, loss:[5.088723]\n",
      "iter 200, loss:[5.1011314]\n",
      "iter 250, loss:[4.7370057]\n",
      "iter 300, loss:[4.7658596]\n",
      "iter 350, loss:[4.865528]\n",
      "iter 400, loss:[4.98389]\n",
      "epoch:3\n",
      "iter 0, loss:[4.7842174]\n",
      "iter 50, loss:[4.7123823]\n",
      "iter 100, loss:[4.467573]\n",
      "iter 150, loss:[4.5247555]\n",
      "iter 200, loss:[4.688441]\n",
      "iter 250, loss:[4.5418425]\n",
      "iter 300, loss:[4.683344]\n",
      "iter 350, loss:[4.620677]\n",
      "iter 400, loss:[4.378727]\n",
      "epoch:4\n",
      "iter 0, loss:[4.1927934]\n",
      "iter 50, loss:[4.3360577]\n",
      "iter 100, loss:[4.3422036]\n",
      "iter 150, loss:[4.1935406]\n",
      "iter 200, loss:[3.9279475]\n",
      "iter 250, loss:[4.060567]\n",
      "iter 300, loss:[3.7683282]\n",
      "iter 350, loss:[3.9795702]\n",
      "iter 400, loss:[4.349891]\n",
      "epoch:5\n",
      "iter 0, loss:[3.70538]\n",
      "iter 50, loss:[3.813654]\n",
      "iter 100, loss:[3.807558]\n",
      "iter 150, loss:[3.879221]\n",
      "iter 200, loss:[4.1971197]\n",
      "iter 250, loss:[3.618608]\n",
      "iter 300, loss:[3.9547596]\n",
      "iter 350, loss:[3.8898044]\n",
      "iter 400, loss:[3.7170234]\n",
      "epoch:6\n",
      "iter 0, loss:[3.9988165]\n",
      "iter 50, loss:[3.799305]\n",
      "iter 100, loss:[3.7779708]\n",
      "iter 150, loss:[3.569619]\n",
      "iter 200, loss:[3.597557]\n",
      "iter 250, loss:[3.2460666]\n",
      "iter 300, loss:[3.543639]\n",
      "iter 350, loss:[3.7020588]\n",
      "iter 400, loss:[3.560639]\n",
      "epoch:7\n",
      "iter 0, loss:[4.000338]\n",
      "iter 50, loss:[3.4925098]\n",
      "iter 100, loss:[3.454872]\n",
      "iter 150, loss:[3.3677359]\n",
      "iter 200, loss:[3.1372507]\n",
      "iter 250, loss:[3.3880277]\n",
      "iter 300, loss:[3.3924785]\n",
      "iter 350, loss:[3.5136948]\n",
      "iter 400, loss:[3.4401946]\n",
      "epoch:8\n",
      "iter 0, loss:[3.3234754]\n",
      "iter 50, loss:[3.1045842]\n",
      "iter 100, loss:[3.2335927]\n",
      "iter 150, loss:[3.1652954]\n",
      "iter 200, loss:[3.1573207]\n",
      "iter 250, loss:[2.967555]\n",
      "iter 300, loss:[2.9638853]\n",
      "iter 350, loss:[3.359198]\n",
      "iter 400, loss:[3.3576903]\n",
      "epoch:9\n",
      "iter 0, loss:[3.4053416]\n",
      "iter 50, loss:[3.28559]\n",
      "iter 100, loss:[3.2341754]\n",
      "iter 150, loss:[3.4945803]\n",
      "iter 200, loss:[3.4042306]\n",
      "iter 250, loss:[3.1475368]\n",
      "iter 300, loss:[3.324573]\n",
      "iter 350, loss:[3.4394846]\n",
      "iter 400, loss:[3.3708265]\n",
      "epoch:10\n",
      "iter 0, loss:[3.0001364]\n",
      "iter 50, loss:[2.991127]\n",
      "iter 100, loss:[3.0722184]\n",
      "iter 150, loss:[3.325819]\n",
      "iter 200, loss:[3.100689]\n",
      "iter 250, loss:[3.5493097]\n",
      "iter 300, loss:[3.4649014]\n",
      "iter 350, loss:[2.9923172]\n",
      "iter 400, loss:[3.0430908]\n",
      "epoch:11\n",
      "iter 0, loss:[3.1742065]\n",
      "iter 50, loss:[3.101646]\n",
      "iter 100, loss:[3.0722806]\n",
      "iter 150, loss:[3.325056]\n",
      "iter 200, loss:[3.1894975]\n",
      "iter 250, loss:[3.078614]\n",
      "iter 300, loss:[3.2159715]\n",
      "iter 350, loss:[3.1791196]\n",
      "iter 400, loss:[3.3101087]\n",
      "epoch:12\n",
      "iter 0, loss:[3.1987045]\n",
      "iter 50, loss:[3.1603284]\n",
      "iter 100, loss:[3.115251]\n",
      "iter 150, loss:[3.2267609]\n",
      "iter 200, loss:[2.8023987]\n",
      "iter 250, loss:[3.1135728]\n",
      "iter 300, loss:[3.124663]\n",
      "iter 350, loss:[3.1108272]\n",
      "iter 400, loss:[2.752792]\n",
      "epoch:13\n",
      "iter 0, loss:[3.085094]\n",
      "iter 50, loss:[2.8488805]\n",
      "iter 100, loss:[3.1250331]\n",
      "iter 150, loss:[3.1948972]\n",
      "iter 200, loss:[2.918927]\n",
      "iter 250, loss:[2.8743672]\n",
      "iter 300, loss:[2.7285495]\n",
      "iter 350, loss:[3.0027294]\n",
      "iter 400, loss:[2.7317867]\n",
      "epoch:14\n",
      "iter 0, loss:[3.1064992]\n",
      "iter 50, loss:[3.2941253]\n",
      "iter 100, loss:[2.9047089]\n",
      "iter 150, loss:[2.9259467]\n",
      "iter 200, loss:[2.72817]\n",
      "iter 250, loss:[2.859048]\n",
      "iter 300, loss:[2.7755802]\n",
      "iter 350, loss:[3.0022492]\n",
      "iter 400, loss:[2.7661226]\n",
      "epoch:15\n",
      "iter 0, loss:[2.6932015]\n",
      "iter 50, loss:[3.0056386]\n",
      "iter 100, loss:[2.880162]\n",
      "iter 150, loss:[3.045475]\n",
      "iter 200, loss:[2.5715647]\n",
      "iter 250, loss:[2.8020825]\n",
      "iter 300, loss:[3.115347]\n",
      "iter 350, loss:[2.8176556]\n",
      "iter 400, loss:[3.3447514]\n",
      "epoch:16\n",
      "iter 0, loss:[2.7985656]\n",
      "iter 50, loss:[2.5079994]\n",
      "iter 100, loss:[2.6029446]\n",
      "iter 150, loss:[2.9382114]\n",
      "iter 200, loss:[2.847636]\n",
      "iter 250, loss:[2.8214068]\n",
      "iter 300, loss:[2.7550635]\n",
      "iter 350, loss:[2.8066204]\n",
      "iter 400, loss:[2.8905272]\n",
      "epoch:17\n",
      "iter 0, loss:[2.943319]\n",
      "iter 50, loss:[2.9674811]\n",
      "iter 100, loss:[3.2992969]\n",
      "iter 150, loss:[2.5251377]\n",
      "iter 200, loss:[2.479341]\n",
      "iter 250, loss:[2.8336058]\n",
      "iter 300, loss:[3.1445017]\n",
      "iter 350, loss:[2.6924486]\n",
      "iter 400, loss:[2.9207923]\n",
      "epoch:18\n",
      "iter 0, loss:[2.986607]\n",
      "iter 50, loss:[2.6938725]\n",
      "iter 100, loss:[2.778695]\n",
      "iter 150, loss:[2.787875]\n",
      "iter 200, loss:[3.1002865]\n",
      "iter 250, loss:[3.0222526]\n",
      "iter 300, loss:[2.618815]\n",
      "iter 350, loss:[2.5167418]\n",
      "iter 400, loss:[2.8799875]\n",
      "epoch:19\n",
      "iter 0, loss:[2.9941392]\n",
      "iter 50, loss:[2.461697]\n",
      "iter 100, loss:[2.6210032]\n",
      "iter 150, loss:[2.914026]\n",
      "iter 200, loss:[2.7009106]\n",
      "iter 250, loss:[2.9732232]\n",
      "iter 300, loss:[2.8785443]\n",
      "iter 350, loss:[2.6244054]\n",
      "iter 400, loss:[2.6331224]\n"
     ]
    }
   ],
   "source": [
    "encoder=Encoder(en_vocab_size,embedding_size)\n",
    "decoder=Decoder(cn_vocab_size,embedding_size)\n",
    "\n",
    "opt=paddle.optimizer.Adam(learning_rate=0.00001,parameters=encoder.parameters()+decoder.parameters())\n",
    "for epoch in  range(epochs):\n",
    "    print(\"epoch:{}\".format(epoch))\n",
    "    perm=np.random.permutation(len(train_en_sents))\n",
    "    train_en_sents_shuffled=train_en_sents[perm]\n",
    "    train_cn_sents_shuffled=train_cn_sents[perm]\n",
    "    train_cn_label_sents_shuffled=train_cn_label_sents[perm]\n",
    "\n",
    "    for iteration in range(train_en_sents_shuffled.shape[0]//batch_size):\n",
    "        x_data=train_en_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "        sent=paddle.to_tensor(x_data)\n",
    "        en_repr=encoder(sent)\n",
    "\n",
    "        x_cn_data=train_cn_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "        x_cn_label_data=train_cn_label_sents_shuffled[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "\n",
    "        # hidden=paddle.zeros([batch_size,1,hidden_size])\n",
    "        # cell=paddle.zeros([batch_size,1,hidden_size])\n",
    "        loss=paddle.zeros([1])\n",
    "\n",
    "        for i in range(MAX_LEN+2):\n",
    "            cn_word=paddle.to_tensor(x_cn_data[:,i:i+1])\n",
    "            cn_word_label=paddle.to_tensor(x_cn_label_data[:,i])\n",
    "\n",
    "            # logits,(hidden,cell)=decoder(cn_word,hidden,cell,en_repr)\n",
    "            logits=decoder(cn_word,en_repr)\n",
    "            step_loss=F.cross_entropy(logits,cn_word_label)\n",
    "            loss+=step_loss\n",
    "        \n",
    "        loss=loss/(MAX_LEN+2)\n",
    "        if(iteration % 50==0):\n",
    "            print(\"iter {}, loss:{}\".format(iteration,loss.numpy()))\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-06T11:23:14.097471Z",
     "iopub.status.busy": "2022-08-06T11:23:14.096989Z",
     "iopub.status.idle": "2022-08-06T11:23:14.187580Z",
     "shell.execute_reply": "2022-08-06T11:23:14.186177Z",
     "shell.execute_reply.started": "2022-08-06T11:23:14.097438Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i m very lonely\n",
      "true: 我很寂寞。\n",
      "pred: 我不是我不是我不是我不是\n",
      "i hope people are satisfied\n",
      "true: 我希望人们满意。\n",
      "pred: 我不是一个。\n",
      "you shouldn t make fun of tom\n",
      "true: 你不该取笑汤姆。\n",
      "pred: 你不不不不不不不不不不不\n",
      "i did something really stupid\n",
      "true: 我做了很蠢的事。\n",
      "pred: 我的。\n",
      "i m here too\n",
      "true: 我也在这里。\n",
      "pred: 我不是我不是我不是我不是\n",
      "i walked as far as the station\n",
      "true: 我一直走到火車站。\n",
      "pred: 我的。\n",
      "he stuck to his promise\n",
      "true: 他信守了承诺.\n",
      "pred: 他的。\n",
      "she gave it her personal attention\n",
      "true: 她親自過問了此事。\n",
      "pred: 她是她是她是她是她是她是\n",
      "i ll drop you off at the station\n",
      "true: 我載你到車站。\n",
      "pred: 我不\n",
      "you can go\n",
      "true: 你可以去了。\n",
      "pred: 你不是你不是你不是你不是\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\r\n",
    "decoder.eval()\r\n",
    "\r\n",
    "num_of_examples_to_evaluate=10\r\n",
    "\r\n",
    "indices=np.random.choice(len(train_en_sents),num_of_examples_to_evaluate,replace=False)\r\n",
    "x_data=train_en_sents[indices]\r\n",
    "sent=paddle.to_tensor(x_data)\r\n",
    "\r\n",
    "en_repr=encoder(sent)\r\n",
    "\r\n",
    "\r\n",
    "word=np.array([[cn_vocab[\"<bos>\"]]]*num_of_examples_to_evaluate)\r\n",
    "word=paddle.to_tensor(word)\r\n",
    "\r\n",
    "# hidden=paddle.zeros([num_of_examples_to_evaluate,1,hidden_size])\r\n",
    "# cell=paddle.zeros([num_of_examples_to_evaluate,1,hidden_size])\r\n",
    "\r\n",
    "decoded_sent=[]\r\n",
    "for i in range(MAX_LEN+2):\r\n",
    "    # logits,(hidden,cell)=decoder(word,hidden,cell,en_repr)\r\n",
    "    logits=decoder(word,en_repr)\r\n",
    "    # print('-'*30)\r\n",
    "    # print(logits.shape)\r\n",
    "    word=paddle.argmax(logits,axis=-1)\r\n",
    "    # print(word.shape)\r\n",
    "    decoded_sent.append(word.numpy())\r\n",
    "    word=paddle.unsqueeze(word,axis=-1)\r\n",
    "    # print(word.shape)\r\n",
    "\r\n",
    "results=np.stack(decoded_sent,axis=1)\r\n",
    "for i in range(num_of_examples_to_evaluate):\r\n",
    "    en_input=' '.join(filtered_pairs[indices[i]][0])\r\n",
    "    ground_truth_translate=''.join(filtered_pairs[indices[i]][1])\r\n",
    "    modle_translate=\"\"\r\n",
    "    for k in results[i]:\r\n",
    "        w=list(cn_vocab)[k]\r\n",
    "        if w!='<pad>' and w!= '<eos>':\r\n",
    "            modle_translate+=w\r\n",
    "    print(en_input)\r\n",
    "    print(\"true:\",ground_truth_translate)\r\n",
    "    print(\"pred:\",modle_translate)\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
